{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying CMU Face Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for MPS (Apple Silicon), CUDA (for Nvidia GPUs), or fallback to CPU\n",
    "\n",
    "We're checking for different device options (MPS, CUDA, or CPU) to ensure that our PyTorch model runs on the most powerful hardware available. Running on a GPU (like CUDA or MPS) significantly speeds up computations, especially for tasks involving large datasets or deep learning models, by performing parallel processing. If no GPU is available, the code falls back to using the CPU, which is slower but still functional.\n",
    "\n",
    "On Mac, newer Apple Silicon chips (M1/M2) support GPU acceleration through Metal Performance Shaders (MPS), which we check for to optimize performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')  # Metal Performance Shaders for Mac\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')  # CUDA for Nvidia GPUs (if available on Mac)\n",
    "else:\n",
    "    device = torch.device('cpu')   # Fallback to CPU\n",
    "\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading/Exploring our data\n",
    "\n",
    "We should resize the images to be 32x32 because the original LeNet-5 architecture expects input images of size 32x32, as it was originally designed for the MNIST dataset, where images have that specific resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),  # Convert image to grayscale\n",
    "    transforms.Resize((32, 32)),  # Resize images to 32x32\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = ImageFolder(root='./face_0/', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 374, Validation set: 124, Testing set: 126\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.6 * len(data))\n",
    "val_size = int(0.2 * len(data))\n",
    "test_size = len(data) - train_size - val_size\n",
    "\n",
    "train_data, val_data, test_data = random_split(data, [train_size, val_size, test_size])\n",
    "\n",
    "print(f\"Training set: {len(train_data)}, Validation set: {len(val_data)}, Testing set: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the LeNet-5 architecture\n",
    "\n",
    "We switched the original 10 output features to 20 in the final fully connected layer because the number of output neurons must match the number of classes in your dataset. The original model had 10 output neurons, suitable for datasets like MNIST with 10 classes. Since your dataset has 20 classes, we need 20 output neurons, with each neuron representing one class, allowing the model to output a score for each of the 20 possible classes.\n",
    "\n",
    "Additionally, I'm also including dropout rate for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify LeNet5 to include dropout, L1/L2 regularization\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, dropout_rate):\n",
    "        super(LeNet5, self).__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Fully connected layers with Dropout\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 20)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu(self.conv1(x)))\n",
    "        x = self.pool2(self.relu(self.conv2(x)))\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Hyperparameter tuning\n",
    "    learning_rate = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    l1_lambda = trial.suggest_float(\"l1_lambda\", 1e-6, 1e-2, log=True)\n",
    "    l2_lambda = trial.suggest_float(\"l2_lambda\", 1e-6, 1e-2, log=True)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.0, 0.5)\n",
    "\n",
    "    # Instantiate the model with tuned parameters\n",
    "    model = LeNet5(dropout_rate).to(device)\n",
    "\n",
    "    # Define the optimizer with L2 regularization\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), \n",
    "        lr=learning_rate, \n",
    "        momentum=0.9, \n",
    "        weight_decay=l2_lambda  # L2 regularization (also known as weight decay)\n",
    "    )\n",
    "\n",
    "    # Loss function with L1 regularization\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Data Loaders (use the previously defined loaders)\n",
    "    train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, (images, labels) in enumerate(train_loader, 0):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # L1 regularization\n",
    "            l1_loss = 0\n",
    "            for param in model.parameters():\n",
    "                l1_loss += torch.sum(torch.abs(param))\n",
    "            loss += l1_lambda * l1_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        trial.report(val_loss, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate results.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-18 13:36:15,974] A new study created in memory with name: no-name-fed62642-20a0-4f32-ba64-b26b901ff1e5\n",
      "[I 2024-09-18 13:36:34,628] Trial 0 finished with value: 3.000635862350464 and parameters: {'lr': 0.004514434262947315, 'l1_lambda': 2.5708069040824766e-05, 'l2_lambda': 8.816498122509794e-06, 'dropout_rate': 0.4516834438704467}. Best is trial 0 with value: 3.000635862350464.\n",
      "[I 2024-09-18 13:36:53,018] Trial 1 finished with value: 3.0007574558258057 and parameters: {'lr': 0.0011525811387040228, 'l1_lambda': 0.0011605095398469771, 'l2_lambda': 0.0010263065347655988, 'dropout_rate': 0.489364635236485}. Best is trial 0 with value: 3.000635862350464.\n",
      "[I 2024-09-18 13:37:11,334] Trial 2 finished with value: 3.003084182739258 and parameters: {'lr': 0.0020671788141021956, 'l1_lambda': 0.0001411568831359299, 'l2_lambda': 0.0005026857802810134, 'dropout_rate': 0.03792366944921827}. Best is trial 0 with value: 3.000635862350464.\n",
      "[I 2024-09-18 13:37:29,559] Trial 3 finished with value: 3.0039570331573486 and parameters: {'lr': 1.9290723654295758e-05, 'l1_lambda': 1.126836659311612e-06, 'l2_lambda': 0.003662129921722219, 'dropout_rate': 0.24689036726947344}. Best is trial 0 with value: 3.000635862350464.\n",
      "[I 2024-09-18 13:37:47,892] Trial 4 finished with value: 2.9947696924209595 and parameters: {'lr': 0.00016551967806151076, 'l1_lambda': 0.0010442815388701854, 'l2_lambda': 0.0019944212194169674, 'dropout_rate': 0.246869482554063}. Best is trial 4 with value: 2.9947696924209595.\n",
      "[I 2024-09-18 13:38:06,255] Trial 5 finished with value: 2.9962743520736694 and parameters: {'lr': 0.004184665358767106, 'l1_lambda': 2.3830579856186274e-05, 'l2_lambda': 7.997021787469404e-05, 'dropout_rate': 0.12165687174145012}. Best is trial 4 with value: 2.9947696924209595.\n",
      "[I 2024-09-18 13:38:24,653] Trial 6 finished with value: 2.99594509601593 and parameters: {'lr': 0.00021518349839360775, 'l1_lambda': 0.00033802930779299335, 'l2_lambda': 0.0003559661303520961, 'dropout_rate': 0.20922224601373202}. Best is trial 4 with value: 2.9947696924209595.\n",
      "[I 2024-09-18 13:38:26,522] Trial 7 pruned. \n",
      "[I 2024-09-18 13:38:28,362] Trial 8 pruned. \n",
      "[I 2024-09-18 13:38:46,769] Trial 9 finished with value: 3.0028244256973267 and parameters: {'lr': 0.00824020487525424, 'l1_lambda': 0.001963205762558938, 'l2_lambda': 0.002890486493447354, 'dropout_rate': 0.3849813744801488}. Best is trial 4 with value: 2.9947696924209595.\n",
      "[I 2024-09-18 13:39:04,937] Trial 10 finished with value: 2.997596025466919 and parameters: {'lr': 0.00039093868828909896, 'l1_lambda': 0.009684425759875563, 'l2_lambda': 1.317902769747209e-06, 'dropout_rate': 0.34526566203913034}. Best is trial 4 with value: 2.9947696924209595.\n",
      "[I 2024-09-18 13:39:23,376] Trial 11 finished with value: 2.997080683708191 and parameters: {'lr': 0.00014877840764266048, 'l1_lambda': 0.0003041503198382923, 'l2_lambda': 0.00014357060288130638, 'dropout_rate': 0.1596918333982736}. Best is trial 4 with value: 2.9947696924209595.\n",
      "[I 2024-09-18 13:39:25,228] Trial 12 pruned. \n",
      "[I 2024-09-18 13:39:43,772] Trial 13 finished with value: 2.997172474861145 and parameters: {'lr': 9.588721291152771e-05, 'l1_lambda': 0.009479927623822474, 'l2_lambda': 3.7911018916817084e-05, 'dropout_rate': 0.2992277357136324}. Best is trial 4 with value: 2.9947696924209595.\n",
      "[I 2024-09-18 13:39:45,633] Trial 14 pruned. \n",
      "[I 2024-09-18 13:40:04,027] Trial 15 finished with value: 2.9971518516540527 and parameters: {'lr': 0.00018349584662383762, 'l1_lambda': 5.060176563809562e-06, 'l2_lambda': 0.00849128703941888, 'dropout_rate': 0.2039141418522732}. Best is trial 4 with value: 2.9947696924209595.\n",
      "[I 2024-09-18 13:40:05,899] Trial 16 pruned. \n",
      "[I 2024-09-18 13:40:24,416] Trial 17 finished with value: 2.9859237670898438 and parameters: {'lr': 0.00019878060666910093, 'l1_lambda': 0.000173830493954671, 'l2_lambda': 0.0004381773422481323, 'dropout_rate': 0.25496347559264027}. Best is trial 17 with value: 2.9859237670898438.\n",
      "[I 2024-09-18 13:40:26,291] Trial 18 pruned. \n",
      "[I 2024-09-18 13:40:44,800] Trial 19 finished with value: 2.98965847492218 and parameters: {'lr': 1.0283381853606796e-05, 'l1_lambda': 0.00014465337121627282, 'l2_lambda': 0.001615668682164284, 'dropout_rate': 0.3756826753345977}. Best is trial 17 with value: 2.9859237670898438.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'lr': 0.00019878060666910093, 'l1_lambda': 0.000173830493954671, 'l2_lambda': 0.0004381773422481323, 'dropout_rate': 0.25496347559264027}\n",
      "CPU times: user 4min 23s, sys: 3.36 s, total: 4min 27s\n",
      "Wall time: 4min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Optuna study\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(f\"Best hyperparameters: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val loss: 2.9859237670898438\n"
     ]
    }
   ],
   "source": [
    "# Best hyperparameters\n",
    "print(f\"Best val loss: {study.best_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
